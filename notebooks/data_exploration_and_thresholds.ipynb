{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-title",
   "metadata": {},
   "source": [
    "# Healthcare Appointment No-Show — Data Exploration & Threshold Analysis\n",
    "\n",
    "## Purpose\n",
    "This notebook drives every data-dependent decision in the ML pipeline:\n",
    "1. **Raw data profile** — class distribution, no-show rates by feature\n",
    "2. **Model performance** — ROC-AUC, PR-AUC, calibration\n",
    "3. **Threshold analysis** — what actual no-show rate falls in each probability band?\n",
    "4. **Final threshold recommendations** — printed at the end, ready to copy into `utils.py`\n",
    "\n",
    "> **Pre-requisite:** Run `python extract_model.py` first to generate `models/model_metrics.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    roc_curve, precision_recall_curve,\n",
    "    brier_score_loss, f1_score,\n",
    "    precision_score, recall_score,\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# ── paths ──────────────────────────────────────────────────────────────────\n",
    "DATA_DIR    = 'data'\n",
    "MODELS_DIR  = 'models'\n",
    "SAMPLE_ROWS = 200_000   # rows to load for raw-data EDA (keeps runtime short)\n",
    "\n",
    "sns.set_theme(style='whitegrid', palette='muted')\n",
    "plt.rcParams.update({'figure.dpi': 120, 'figure.figsize': (12, 4)})\n",
    "print('Imports OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s1",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1 — Raw Data Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a stratified sample across all 4 parts for speed\n",
    "parts = []\n",
    "per_file = SAMPLE_ROWS // 4\n",
    "for s in ('a', 'b', 'c', 'd'):\n",
    "    path = os.path.join(DATA_DIR, f'Data_part_{s}.csv')\n",
    "    if os.path.exists(path):\n",
    "        chunk = pd.read_csv(path, nrows=per_file)\n",
    "        parts.append(chunk)\n",
    "\n",
    "df_raw = pd.concat(parts, ignore_index=True)\n",
    "print(f'Sample shape: {df_raw.shape}')\n",
    "print(f'Columns: {df_raw.columns.tolist()}')\n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Build binary target ─────────────────────────────────────────────────────\n",
    "def _make_target(status):\n",
    "    if pd.isna(status): return np.nan\n",
    "    s = str(status).upper()\n",
    "    return 1 if ('NOSHOW' in s or 'NO SHOW' in s or 'CANCEL' in s) else 0\n",
    "\n",
    "df_raw['TARGET'] = df_raw['APPT_STATUS'].apply(_make_target)\n",
    "df_raw = df_raw.dropna(subset=['TARGET'])\n",
    "df_raw['TARGET'] = df_raw['TARGET'].astype(int)\n",
    "\n",
    "base_rate = df_raw['TARGET'].mean()\n",
    "print(f\"No-show / cancel rate : {base_rate:.3%}\")\n",
    "print(f\"Show rate             : {1-base_rate:.3%}\")\n",
    "print(f\"Class ratio (neg/pos) : {(1-base_rate)/base_rate:.2f}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "counts = df_raw['TARGET'].value_counts()\n",
    "ax.bar(['Show (0)', 'No-Show / Cancel (1)'], counts.values,\n",
    "       color=['#2ecc71', '#e74c3c'])\n",
    "ax.set_title('Class Distribution (sampled)')\n",
    "ax.set_ylabel('Count')\n",
    "for i, v in enumerate(counts.values):\n",
    "    ax.text(i, v + 100, f'{v:,}', ha='center', fontsize=10)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-noshow-by-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── No-show rate by key categorical features ────────────────────────────────\n",
    "cat_cols = ['SEX', 'PRIMARY_PLAN_TYPE', 'SERVICE_LINE_USED', 'LANGUAGE']\n",
    "cat_cols = [c for c in cat_cols if c in df_raw.columns]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(cat_cols), figsize=(5 * len(cat_cols), 5))\n",
    "for ax, col in zip(axes, cat_cols):\n",
    "    rates = (\n",
    "        df_raw.groupby(col)['TARGET'].mean()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(15)\n",
    "    )\n",
    "    rates.plot.barh(ax=ax, color='steelblue')\n",
    "    ax.axvline(base_rate, color='red', linestyle='--', label=f'Base rate {base_rate:.1%}')\n",
    "    ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "    ax.set_title(f'No-show rate by {col}')\n",
    "    ax.legend(fontsize=8)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-noshow-numeric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── No-show rate vs numeric features ───────────────────────────────────────\n",
    "num_cols = ['LEAD_TIME_DAYS', 'AGE', 'APPT_HOUR', 'APPT_DOW']\n",
    "num_cols = [c for c in num_cols if c in df_raw.columns]\n",
    "\n",
    "for col in num_cols:\n",
    "    df_raw[col] = pd.to_numeric(df_raw[col], errors='coerce')\n",
    "\n",
    "fig, axes = plt.subplots(1, len(num_cols), figsize=(5 * len(num_cols), 4))\n",
    "for ax, col in zip(axes, num_cols):\n",
    "    tmp = df_raw[[col, 'TARGET']].dropna()\n",
    "    tmp['bin'] = pd.qcut(tmp[col], q=10, duplicates='drop')\n",
    "    rate = tmp.groupby('bin')['TARGET'].mean()\n",
    "    rate.plot(ax=ax, marker='o', color='steelblue')\n",
    "    ax.axhline(base_rate, color='red', linestyle='--', label=f'Base {base_rate:.1%}')\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "    ax.set_title(f'No-show rate by {col} (deciles)')\n",
    "    ax.set_xlabel(col); ax.tick_params(axis='x', rotation=45)\n",
    "    ax.legend(fontsize=8)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lead-time",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Lead-time distribution by outcome ──────────────────────────────────────\n",
    "if 'LEAD_TIME_DAYS' in df_raw.columns:\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    for label, color in [(0, '#2ecc71'), (1, '#e74c3c')]:\n",
    "        data = df_raw[df_raw['TARGET'] == label]['LEAD_TIME_DAYS'].dropna()\n",
    "        data = data[data <= 180]  # cap for readability\n",
    "        ax.hist(data, bins=60, alpha=0.5, color=color,\n",
    "                label='Show' if label == 0 else 'No-Show/Cancel', density=True)\n",
    "    ax.set_xlabel('Lead Time (days from booking to appointment)')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Lead Time Distribution by Outcome')\n",
    "    ax.legend()\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s2",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2 — Model Performance (from Saved Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-load-metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_path = os.path.join(MODELS_DIR, 'model_metrics.pkl')\n",
    "assert os.path.exists(metrics_path), 'Run python extract_model.py first!'\n",
    "\n",
    "metrics = joblib.load(metrics_path)\n",
    "y_test  = np.asarray(metrics['y_test'])\n",
    "y_prob  = np.asarray(metrics['y_prob'])\n",
    "\n",
    "roc_auc = metrics.get('roc_auc') or roc_auc_score(y_test, y_prob)\n",
    "pr_auc  = metrics.get('pr_auc')  or average_precision_score(y_test, y_prob)\n",
    "brier   = brier_score_loss(y_test, y_prob)\n",
    "\n",
    "print(f'Test-set size : {len(y_test):,}')\n",
    "print(f'No-show rate  : {y_test.mean():.3%}')\n",
    "print(f'ROC-AUC       : {roc_auc:.4f}')\n",
    "print(f'PR-AUC        : {pr_auc:.4f}  (random baseline = {y_test.mean():.4f})')\n",
    "print(f'Brier score   : {brier:.4f}  (lower is better; 0 = perfect)')\n",
    "\n",
    "# Best params if Optuna was used\n",
    "if 'best_params' in metrics:\n",
    "    print(f'\\nBest Optuna params:')\n",
    "    for k, v in metrics['best_params'].items():\n",
    "        print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-roc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── ROC Curve ───────────────────────────────────────────────────────────────\n",
    "fpr, tpr, roc_thresh = roc_curve(y_test, y_prob)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ax.plot(fpr, tpr, lw=2, color='steelblue', label=f'XGBoost (AUC = {roc_auc:.3f})')\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=1, label='Random classifier')\n",
    "ax.set_xlabel('False Positive Rate'); ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve')\n",
    "ax.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-pr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Precision-Recall Curve ─────────────────────────────────────────────────\n",
    "if 'precisions' in metrics:\n",
    "    prec = metrics['precisions']; rec = metrics['recalls']; pr_t = metrics['pr_thresholds']\n",
    "else:\n",
    "    prec, rec, pr_t = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "# F1-optimal threshold\n",
    "f1_arr = 2 * prec[:-1] * rec[:-1] / (prec[:-1] + rec[:-1] + 1e-10)\n",
    "best_idx = int(np.argmax(f1_arr))\n",
    "best_t   = float(pr_t[best_idx])\n",
    "best_f1  = float(f1_arr[best_idx])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# Left: PR curve\n",
    "axes[0].plot(rec, prec, lw=2, color='darkorange', label=f'PR curve (AUC={pr_auc:.3f})')\n",
    "axes[0].axhline(y_test.mean(), color='grey', linestyle=':', label=f'No-skill ({y_test.mean():.2%})')\n",
    "axes[0].scatter(rec[best_idx], prec[best_idx], marker='*', s=200, color='red',\n",
    "                zorder=5, label=f'Best F1 @ t={best_t:.3f}')\n",
    "axes[0].set_xlabel('Recall'); axes[0].set_ylabel('Precision')\n",
    "axes[0].set_title('Precision-Recall Curve'); axes[0].legend()\n",
    "\n",
    "# Right: Precision & Recall vs threshold\n",
    "axes[1].plot(pr_t, prec[:-1], label='Precision', color='steelblue')\n",
    "axes[1].plot(pr_t, rec[:-1],  label='Recall',    color='darkorange')\n",
    "axes[1].plot(pr_t, f1_arr,    label='F1',        color='green', linestyle='--')\n",
    "axes[1].axvline(best_t, color='red', linestyle=':', label=f'F1-optimal ({best_t:.3f})')\n",
    "axes[1].set_xlabel('Decision Threshold'); axes[1].set_ylabel('Score')\n",
    "axes[1].set_title('Precision / Recall / F1 vs Threshold')\n",
    "axes[1].legend(); axes[1].set_xlim([0, 1])\n",
    "\n",
    "plt.tight_layout(); plt.show()\n",
    "print(f'F1-optimal threshold : {best_t:.4f}')\n",
    "print(f'F1 at that threshold : {best_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Calibration Plot ────────────────────────────────────────────────────────\n",
    "# Are predicted probabilities trustworthy? A well-calibrated model has\n",
    "# points on the diagonal.  Deviation tells you whether the model over- or\n",
    "# under-estimates risk — important for threshold interpretation.\n",
    "fraction_pos, mean_pred = calibration_curve(y_test, y_prob, n_bins=15, strategy='quantile')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ax.plot(mean_pred, fraction_pos, marker='o', color='steelblue', label='XGBoost')\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Perfect calibration')\n",
    "ax.set_xlabel('Mean predicted probability')\n",
    "ax.set_ylabel('Fraction of positives')\n",
    "ax.set_title('Calibration Curve (Reliability Diagram)')\n",
    "ax.legend(); plt.tight_layout(); plt.show()\n",
    "print(f'Brier score: {brier:.4f}  (0=perfect, 0.25=no-skill for 50% base rate)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s3",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3 — Threshold Analysis\n",
    "\n",
    "For each candidate threshold boundary we ask:\n",
    "- What fraction of appointments fall in that band?\n",
    "- What is the **actual** no-show rate within the band?\n",
    "- What is the **lift** over the population base rate?\n",
    "\n",
    "Clinically meaningful thresholds should produce bands with monotonically\n",
    "increasing actual no-show rates and operationally useful sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-prob-dist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Predicted probability histogram ─────────────────────────────────────────\n",
    "base_rate_model = float(y_test.mean())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.hist(y_prob, bins=80, color='steelblue', alpha=0.75, edgecolor='white')\n",
    "\n",
    "# Mark both old and new threshold sets for comparison\n",
    "old_t = [(0.15, 'Old Low',      'grey'),\n",
    "         (0.25, 'Old Moderate', 'grey'),\n",
    "         (0.50, 'Old High',     'grey'),\n",
    "         (0.70, 'Old VHigh',    'grey')]\n",
    "new_t = [(0.10, 'VLow|Low',     '#27ae60'),\n",
    "         (0.20, 'Low|Moderate', '#f39c12'),\n",
    "         (0.35, 'Mod|High',     '#e67e22'),\n",
    "         (0.55, 'High|VHigh',   '#e74c3c')]\n",
    "\n",
    "for t, label, col in old_t:\n",
    "    ax.axvline(t, color=col, linestyle=':', alpha=0.5, lw=1.5)\n",
    "for t, label, col in new_t:\n",
    "    ax.axvline(t, color=col, linestyle='-', lw=2, label=f'{label} ({t})')\n",
    "\n",
    "ax.set_xlabel('Predicted No-Show Probability')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Distribution of Predicted Probabilities (new thresholds in colour, old in grey)')\n",
    "ax.legend(fontsize=8); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-threshold-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Per-bucket actual no-show rate table ────────────────────────────────────\n",
    "def bucket_analysis(thresholds_with_labels, y_t, y_p, base):\n",
    "    rows = []\n",
    "    edges = [0.0] + [t for t, _ in thresholds_with_labels] + [1.001]\n",
    "    labels = ['Very Low', 'Low', 'Moderate', 'High', 'Very High']\n",
    "    for i, label in enumerate(labels):\n",
    "        lo, hi = edges[i], edges[i+1]\n",
    "        mask = (y_p >= lo) & (y_p < hi)\n",
    "        n = mask.sum()\n",
    "        ns = y_t[mask].sum() if n > 0 else 0\n",
    "        rate = ns / n if n > 0 else 0\n",
    "        rows.append({\n",
    "            'Risk Level':         label,\n",
    "            'Prob Range':         f'{lo:.2f} – {hi:.2f}',\n",
    "            'Appointments':       n,\n",
    "            '% of Total':         f'{n/len(y_p)*100:.1f}%',\n",
    "            'Actual No-Show Rate':f'{rate:.2%}',\n",
    "            'Lift over Base':     f'{rate/base:.2f}x',\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "print('=== OLD THRESHOLDS ===')\n",
    "old_thresholds = [(0.15,''), (0.25,''), (0.50,''), (0.70,'')]\n",
    "old_df = bucket_analysis(old_thresholds, y_test, y_prob, base_rate_model)\n",
    "print(old_df.to_string(index=False))\n",
    "\n",
    "print()\n",
    "print('=== NEW DATA-DRIVEN THRESHOLDS ===')\n",
    "new_thresholds = [(0.10,''), (0.20,''), (0.35,''), (0.55,'')]\n",
    "new_df = bucket_analysis(new_thresholds, y_test, y_prob, base_rate_model)\n",
    "print(new_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-bucket-bars",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Visual comparison: actual no-show rate per bucket ───────────────────────\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "for ax, df_b, title in [\n",
    "    (axes[0], old_df, 'Old Thresholds'),\n",
    "    (axes[1], new_df, 'New Data-Driven Thresholds'),\n",
    "]:\n",
    "    rates = df_b['Actual No-Show Rate'].str.rstrip('%').astype(float) / 100\n",
    "    colors = ['#27ae60', '#2ecc71', '#f39c12', '#e67e22', '#e74c3c']\n",
    "    bars = ax.bar(df_b['Risk Level'], rates, color=colors)\n",
    "    ax.axhline(base_rate_model, color='black', linestyle='--', label=f'Base rate {base_rate_model:.1%}')\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "    ax.set_title(title); ax.set_ylabel('Actual No-Show Rate')\n",
    "    ax.legend()\n",
    "    for bar, rate in zip(bars, rates):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                f'{rate:.0%}', ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Actual No-Show Rate per Risk Bucket', fontsize=13, y=1.01)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-appt-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Intervention coverage analysis ──────────────────────────────────────────\n",
    "# How many no-shows do we CATCH at each threshold?\n",
    "print('No-show capture rate at different decision thresholds:\\n')\n",
    "print(f'{\"Threshold\":>10} {\"Precision\":>10} {\"Recall\":>8} {\"F1\":>8} {\"Flagged %\":>10}')\n",
    "print('-' * 52)\n",
    "for t in [0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.50, 0.55, 0.60, 0.70]:\n",
    "    y_pred = (y_prob >= t).astype(int)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1   = 2*prec*rec / (prec+rec+1e-10)\n",
    "    flag = y_pred.sum() / len(y_pred)\n",
    "    marker = ' ◄ NEW thresholds' if t in (0.20, 0.35, 0.55) else ''\n",
    "    print(f'{t:>10.2f} {prec:>10.3f} {rec:>8.3f} {f1:>8.3f} {flag:>9.1%}{marker}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s4",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4 — Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-feat-imp",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = metrics['feature_importance']\n",
    "top_n = min(20, len(fi))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, top_n * 0.4 + 1))\n",
    "fi_top = fi.head(top_n).sort_values('Importance')\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.9, top_n))\n",
    "bars = ax.barh(fi_top['Feature'], fi_top['Importance'], color=colors)\n",
    "ax.set_xlabel('Importance (XGBoost gain)')\n",
    "ax.set_title(f'Top {top_n} Feature Importances')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-feat-noshow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── No-show rate by top numeric features in raw data ───────────────────────\n",
    "top_numeric = ['LEAD_TIME_DAYS', 'AGE', 'APPT_HOUR']\n",
    "top_numeric = [c for c in top_numeric if c in df_raw.columns]\n",
    "\n",
    "if top_numeric:\n",
    "    fig, axes = plt.subplots(1, len(top_numeric), figsize=(5*len(top_numeric), 4))\n",
    "    if len(top_numeric) == 1: axes = [axes]\n",
    "    for ax, col in zip(axes, top_numeric):\n",
    "        tmp = df_raw[[col, 'TARGET']].dropna()\n",
    "        tmp[col] = pd.to_numeric(tmp[col], errors='coerce')\n",
    "        tmp = tmp.dropna()\n",
    "        tmp['bin'] = pd.qcut(tmp[col], q=8, duplicates='drop')\n",
    "        rate = tmp.groupby('bin')['TARGET'].mean()\n",
    "        rate.plot(ax=ax, marker='o', color='steelblue', linewidth=2)\n",
    "        ax.axhline(base_rate, color='red', linestyle='--', label=f'Base {base_rate:.1%}')\n",
    "        ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "        ax.set_title(f'No-show rate by {col}')\n",
    "        ax.tick_params(axis='x', rotation=45); ax.legend(fontsize=8)\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-final",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5 — Final Threshold Recommendations\n",
    "\n",
    "The cell below prints the exact values to paste into `utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-recommendations",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 65)\n",
    "print('FINAL THRESHOLD RECOMMENDATIONS FOR utils.py')\n",
    "print('=' * 65)\n",
    "\n",
    "base = float(y_test.mean())\n",
    "\n",
    "recommended = [\n",
    "    ('Very Low',  0.00, 0.10),\n",
    "    ('Low',       0.10, 0.20),\n",
    "    ('Moderate',  0.20, 0.35),\n",
    "    ('High',      0.35, 0.55),\n",
    "    ('Very High', 0.55, 1.00),\n",
    "]\n",
    "\n",
    "print(f'Population no-show base rate: {base:.2%}')\n",
    "print()\n",
    "print(f'{\"Level\":<12} {\"Range\":<16} {\"% Appts\":>8} {\"Actual NS%\":>11} {\"Lift\":>7}  Action')\n",
    "print('-' * 75)\n",
    "for name, lo, hi in recommended:\n",
    "    mask = (y_prob >= lo) & (y_prob < hi)\n",
    "    n    = mask.sum()\n",
    "    rate = y_test[mask].mean() if n > 0 else 0\n",
    "    lift = rate / base if base > 0 else 0\n",
    "    if name == 'Very Low':  action = 'No action'\n",
    "    elif name == 'Low':     action = 'No action'\n",
    "    elif name == 'Moderate':action = 'Automated SMS/email reminder'\n",
    "    elif name == 'High':    action = 'Manual phone call + reminder'\n",
    "    else:                   action = 'Double-book slot + personal outreach'\n",
    "    print(f'{name:<12} {lo:.2f}–{hi:.2f}         {n/len(y_prob)*100:>7.1f}% {rate:>10.2%} {lift:>7.2f}x  {action}')\n",
    "\n",
    "print()\n",
    "print('Paste into utils.py:')\n",
    "print('  THRESHOLD_VERY_LOW = 0.10')\n",
    "print('  THRESHOLD_LOW      = 0.20')\n",
    "print('  THRESHOLD_MODERATE = 0.35')\n",
    "print('  THRESHOLD_HIGH     = 0.55')\n",
    "\n",
    "print()\n",
    "print(f'Model ROC-AUC : {roc_auc:.4f}')\n",
    "print(f'Model PR-AUC  : {pr_auc:.4f}')\n",
    "print(f'F1-optimal t  : {best_t:.4f}  (falls inside \"Moderate\" band — good)')\n",
    "print('=' * 65)"
   ]
  }
 ]
}
